# ffnn-optimization-algos
Two feedforward neural network weight optimization algorithm implementations:
1. Stochastic Gradient Descent
2. Conjugate Gradients with Fletcher Reeves updates.

Algorihtms implemented for shallow neural networks with one hidden layer only.
Implements early stopping to prevent overfitting.
